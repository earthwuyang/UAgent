"""
Anti-Fraud Prompts and Requirements for AI Scientist
Prevents synthetic data generation and enforces real experimentation
"""

REAL_EXPERIMENTATION_REQUIREMENTS = """
üö® CRITICAL ANTI-FRAUD REQUIREMENTS - VIOLATION WILL INVALIDATE ALL RESULTS üö®

You are conducting REAL SCIENTIFIC RESEARCH. Any form of data simulation, synthetic generation, or fake results is SCIENTIFIC FRAUD and is absolutely PROHIBITED.

üê≥ DOCKER ENVIRONMENT REQUIREMENT (CRITICAL):
- ALL experiments MUST be conducted inside Docker containers
- This ensures proper dependency management and eliminates "missing module" errors
- NO excuses for missing psycopg2, build tools, or system dependencies
- Create Dockerfile with ALL required packages before starting experiments

MANDATORY REQUIREMENTS:

1. üö´ NEVER GENERATE SYNTHETIC DATA
   - NO use of np.random, random.choice, or any synthetic data generation
   - NO fake datasets, mock data, or simulated results
   - NO randomly generated ground truth labels
   - ALL data must come from real sources, real systems, or real benchmarks

2. üîß REAL SYSTEM IMPLEMENTATION REQUIRED
   - If your idea claims to "modify PostgreSQL kernel" ‚Üí You MUST git clone PostgreSQL source code
   - If your idea claims to "modify system X" ‚Üí You MUST git clone and build system X
   - If your idea claims "kernel modifications" ‚Üí You MUST show actual source code changes
   - NO claiming system modifications without actual git operations and builds

3. üìä REAL DATA SOURCES ONLY
   - Use real datasets: TPC-H, TPC-C, academic benchmarks, public datasets
   - Connect to real databases: PostgreSQL, MySQL, SQLite with real schemas
   - Load real benchmark data, not randomly generated numbers
   - Document all data sources and how they were obtained

4. üî¨ REAL MEASUREMENTS REQUIRED
   - Measure actual execution times, not simulated times
   - Use real performance counters, not random numbers
   - Benchmark real systems, not mock implementations
   - Show actual system behavior, not theoretical simulations

5. üíª SOURCE CODE REQUIREMENTS
   - If claiming system modifications: git clone, git diff, make, configure
   - Show actual patches, actual compilation, actual installation
   - Provide evidence of real system integration
   - NO claiming to modify code without showing the actual modifications

VALIDATION CHECKS:
Before any experiment runs, your code will be validated for:
- ‚ùå Synthetic data generation patterns
- ‚ùå Random ground truth generation
- ‚ùå Missing source code when claiming modifications
- ‚ùå Missing git operations when claiming to modify systems
- ‚ùå Lack of real data sources

EXAMPLES OF FRAUD (ABSOLUTELY PROHIBITED):
‚ùå data = {"feature": np.random.rand(1000), "label": np.random.choice([0,1], 1000)}
‚ùå ground_truth = np.random.choice(["PostgreSQL", "DuckDB"], num_samples)
‚ùå # Simulating PostgreSQL modification (without actually doing it)
‚ùå execution_time = np.random.uniform(0.1, 2.0)  # Fake timing

EXAMPLES OF REAL RESEARCH (REQUIRED):
‚úÖ git clone https://github.com/postgres/postgres.git
‚úÖ df = pd.read_csv("tpch_benchmark_results.csv")
‚úÖ conn = psycopg2.connect("postgresql://localhost:5432/tpch")
‚úÖ actual_time = time.time(); run_query(); elapsed = time.time() - actual_time

If you cannot implement real experiments (e.g., don't have access to required systems),
you must clearly state this limitation rather than generating fake data.

REMEMBER: Science requires REAL DATA and REAL EXPERIMENTS. Synthetic data is only
acceptable for ablation studies AFTER establishing results with real data.
"""

POSTGRESQL_MODIFICATION_REQUIREMENTS = """
üêò POSTGRESQL MODIFICATION REQUIREMENTS

üê≥ CRITICAL: ALL PostgreSQL modifications MUST be done inside Docker containers
Use the enhanced Docker setup provided in the HTAP requirements section.

If your research idea involves modifying PostgreSQL:

1. MANDATORY SOURCE CODE OPERATIONS (INSIDE DOCKER):
   ```bash
   git clone https://github.com/postgres/postgres.git
   cd postgres
   git checkout REL_16_STABLE  # or appropriate version
   ```

2. REQUIRED BUILD PROCESS:
   ```bash
   ./configure --prefix=/usr/local/pgsql --enable-debug
   make -j$(nproc)
   make install
   ```

3. ACTUAL CODE MODIFICATIONS:
   - Modify specific source files (e.g., src/backend/optimizer/plan/planner.c)
   - Show actual patches with git diff
   - Document exact changes made
   - Explain why each change was necessary

4. EVIDENCE OF REAL MODIFICATION:
   - Git commits showing your changes
   - Compilation logs
   - Before/after comparison
   - Working modified PostgreSQL instance

5. REAL BENCHMARKING:
   - Load real data (TPC-H, TPC-C, etc.)
   - Run actual queries on both vanilla and modified PostgreSQL
   - Measure real execution times
   - Compare real performance metrics

NO SHORTCUTS - NO SYNTHETIC SUBSTITUTES - NO FAKE MODIFICATIONS
"""

HTAP_RESEARCH_REQUIREMENTS = """
üîÑ HTAP RESEARCH REQUIREMENTS - STEP-BY-STEP IMPLEMENTATION GUIDE

For HTAP (Hybrid Transactional/Analytical Processing) research, follow this EXACT sequence:

üìã PHASE 1: INFRASTRUCTURE SETUP (MANDATORY - USE DOCKER)

üê≥ **CRITICAL: Use Docker for Environment Isolation and Dependency Management**

1. **Create Docker Environment for PostgreSQL Development:**
   ```bash
   # Create Dockerfile for PostgreSQL development environment
   cat > Dockerfile << 'EOF'
FROM ubuntu:22.04

# Install required system packages
RUN apt-get update && apt-get install -y \
    build-essential \
    git \
    libreadline-dev \
    zlib1g-dev \
    libssl-dev \
    libxml2-dev \
    libxslt1-dev \
    libicu-dev \
    pkg-config \
    python3 \
    python3-pip \
    python3-dev \
    postgresql-client \
    wget \
    curl \
    sudo \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
RUN pip3 install psycopg2-binary pandas numpy scikit-learn lightgbm

# Set working directory
WORKDIR /workspace

# Create non-root user
RUN useradd -m -s /bin/bash researcher && \
    usermod -aG sudo researcher && \
    echo "researcher ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers

USER researcher
EOF

   # Build and run the container
   docker build -t postgres-research .
   docker run -it --name postgres-experiment -v $(pwd):/workspace postgres-research bash
   ```

2. **PostgreSQL Installation & Setup (Inside Container):**
   ```bash
   # Clone PostgreSQL source
   git clone https://github.com/postgres/postgres.git
   cd postgres
   git checkout REL_16_STABLE

   # Configure and build PostgreSQL
   ./configure --prefix=/home/researcher/pgsql --enable-debug --enable-cassert
   make -j$(nproc)
   make install

   # Add PostgreSQL to PATH
   echo 'export PATH=/home/researcher/pgsql/bin:$PATH' >> ~/.bashrc
   export PATH=/home/researcher/pgsql/bin:$PATH

   # Initialize and start database
   initdb -D /home/researcher/pgsql/data
   pg_ctl -D /home/researcher/pgsql/data -l /home/researcher/pgsql/logfile start

   # Create database
   createdb tpch
   ```

3. **pg_duckdb Extension Setup (Inside Container):**
   ```bash
   # Install DuckDB development dependencies
   sudo apt-get update && sudo apt-get install -y cmake

   # Clone and build pg_duckdb
   cd /workspace
   git clone https://github.com/duckdb/pg_duckdb.git
   cd pg_duckdb

   # Set PostgreSQL config
   export PG_CONFIG=/home/researcher/pgsql/bin/pg_config

   # Build and install extension
   make install
   ```

4. **Database Schema Creation (Inside Container):**
   ```bash
   # Connect to database and create extension
   psql -d tpch -c "CREATE EXTENSION pg_duckdb;"
   psql -d tpch -c "CREATE SCHEMA tpch_postgres;"
   psql -d tpch -c "CREATE SCHEMA tpch_duckdb;"
   ```

üìä PHASE 2: REAL BENCHMARK DATA LOADING (MANDATORY - INSIDE CONTAINER)

1. **Download TPC-H Benchmark (Inside Container):**
   ```bash
   cd /workspace
   git clone https://github.com/gregrahn/tpch-kit.git
   cd tpch-kit/dbgen

   # Patch makefile for modern systems
   cp makefile.suite Makefile
   sed -i 's/CC.*=/CC = gcc/' Makefile
   sed -i 's/DATABASE.*=/DATABASE = POSTGRESQL/' Makefile
   sed -i 's/MACHINE.*=/MACHINE = LINUX/' Makefile
   sed -i 's/WORKLOAD.*=/WORKLOAD = TPCH/' Makefile

   make
   ./dbgen -s 0.1  # Generate 100MB dataset for testing
   ```

2. **Load Data into Both Engines:**
   ```sql
   -- Load into PostgreSQL tables
   \\copy tpch_postgres.lineitem from 'lineitem.tbl' with delimiter '|';
   \\copy tpch_postgres.orders from 'orders.tbl' with delimiter '|';
   -- ... (all TPC-H tables)

   -- Create DuckDB foreign tables
   CREATE FOREIGN TABLE tpch_duckdb.lineitem (...) SERVER duckdb_server;
   ```

3. **Verify Data Integrity:**
   ```sql
   SELECT count(*) FROM tpch_postgres.lineitem;  -- Should match TPC-H specs
   SELECT count(*) FROM tpch_duckdb.lineitem;    -- Should match above
   ```

üîç PHASE 3: QUERY FEATURE EXTRACTION (CRITICAL)
1. **Implement PostgreSQL Query Hooks:**
   ```c
   // Modify src/backend/optimizer/plan/planner.c
   static PlannedStmt *
   standard_planner(Query *parse, int cursorOptions, ParamListInfo boundParams)
   {
       // Extract query features here:
       int num_joins = count_joins(parse);
       int num_aggregates = count_aggregates(parse);
       double estimated_rows = estimate_cardinality(parse);

       // Log features for training data
       log_query_features(parse, num_joins, num_aggregates, estimated_rows);

       return standard_planner_original(parse, cursorOptions, boundParams);
   }
   ```

2. **Create Feature Extraction Functions:**
   ```c
   typedef struct QueryFeatures {
       int num_tables;
       int num_joins;
       int num_aggregates;
       int num_columns_accessed;
       double estimated_rows;
       bool has_group_by;
       bool has_order_by;
       JoinType primary_join_type;
   } QueryFeatures;
   ```

‚ö° PHASE 4: ROUTING IMPLEMENTATION (REQUIRED)
1. **Implement Dual Execution Engine:**
   ```python
   import psycopg2
   import time

   class HTAPRouter:
       def __init__(self):
           self.pg_conn = psycopg2.connect("postgresql://localhost:5432/tpch")
           self.duckdb_conn = psycopg2.connect("postgresql://localhost:5432/tpch")

       def execute_on_postgres(self, query):
           start_time = time.time()
           cursor = self.pg_conn.cursor()
           cursor.execute(query)
           result = cursor.fetchall()
           end_time = time.time()
           return result, end_time - start_time

       def execute_on_duckdb(self, query):
           # Rewrite query to use DuckDB foreign tables
           duckdb_query = self.rewrite_for_duckdb(query)
           start_time = time.time()
           cursor = self.duckdb_conn.cursor()
           cursor.execute(duckdb_query)
           result = cursor.fetchall()
           end_time = time.time()
           return result, end_time - start_time
   ```

üìà PHASE 5: TRAINING DATA COLLECTION (ESSENTIAL)
1. **Execute ALL TPC-H Queries on BOTH Engines:**
   ```python
   def collect_training_data():
       tpch_queries = load_tpch_queries()  # Q1-Q22
       training_data = []

       for query in tpch_queries:
           # Extract features
           features = extract_query_features(query)

           # Execute on PostgreSQL
           pg_result, pg_time = router.execute_on_postgres(query)

           # Execute on DuckDB
           duck_result, duck_time = router.execute_on_duckdb(query)

           # Verify results match
           assert results_match(pg_result, duck_result)

           # Create training record
           faster_engine = "DuckDB" if duck_time < pg_time else "PostgreSQL"

           training_data.append({
               'features': features,
               'postgres_time': pg_time,
               'duckdb_time': duck_time,
               'faster_engine': faster_engine
           })

       return training_data
   ```

ü§ñ PHASE 6: MODEL TRAINING (REQUIRED)
1. **Train Routing Model:**
   ```python
   import lightgbm as lgb
   from sklearn.model_selection import train_test_split

   def train_routing_model(training_data):
       # Prepare features and labels
       X = [record['features'] for record in training_data]
       y = [1 if record['faster_engine'] == 'DuckDB' else 0 for record in training_data]

       # Split data
       X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

       # Train LightGBM model
       model = lgb.LGBMClassifier(n_estimators=100, random_state=42)
       model.fit(X_train, y_train)

       # Evaluate accuracy
       accuracy = model.score(X_test, y_test)
       print(f"Routing accuracy: {accuracy:.3f}")

       return model
   ```

üìä PHASE 7: EVALUATION METRICS (MANDATORY)
1. **Define Success Metrics:**
   ```python
   def evaluate_routing_system():
       metrics = {}

       # Routing accuracy
       correct_predictions = 0
       total_predictions = 0

       # End-to-end performance
       total_speedup = 0
       baseline_time = 0
       routed_time = 0

       for query in test_queries:
           predicted_engine = model.predict_engine(query)
           actual_faster = determine_faster_engine(query)

           if predicted_engine == actual_faster:
               correct_predictions += 1
           total_predictions += 1

           # Measure actual performance
           routed_exec_time = execute_with_routing(query)
           baseline_exec_time = execute_on_postgres_only(query)

           total_speedup += baseline_exec_time / routed_exec_time

       metrics['routing_accuracy'] = correct_predictions / total_predictions
       metrics['average_speedup'] = total_speedup / len(test_queries)
       metrics['routing_overhead'] = measure_routing_overhead()

       return metrics
   ```

‚ö†Ô∏è CRITICAL SUCCESS CRITERIA:
- ‚úÖ **Real PostgreSQL source code modification** (git commits required)
- ‚úÖ **Real TPC-H data loading** (verifiable row counts)
- ‚úÖ **Actual query execution** on both engines (timing logs required)
- ‚úÖ **Measured routing accuracy** >85% (real predictions vs real outcomes)
- ‚úÖ **Demonstrated speedup** >1.5x (real performance improvement)

üö´ AUTOMATIC FAILURE CONDITIONS:
- ‚ùå Any use of synthetic/random data
- ‚ùå Claims of system modification without git history
- ‚ùå Fake performance numbers or simulated timing
- ‚ùå Mock implementations instead of real systems

IMPLEMENTATION VERIFICATION:
Your code will be automatically scanned for:
1. Git operations (`git clone`, `git commit`)
2. Real data loading (`COPY FROM`, `INSERT INTO`)
3. Actual query execution (database connections)
4. Performance measurement (timing code)
5. Model training on real data (no random labels)

NO SIMULATED WORKLOADS - NO FAKE PERFORMANCE DATA - NO MOCK ROUTING - REAL RESEARCH ONLY
"""

DOCKER_MANDATORY_REQUIREMENTS = """
üê≥üö® DOCKER ENVIRONMENT IS MANDATORY üö®üê≥

CRITICAL: Your previous experiments failed because of missing dependencies (psycopg2, build tools, etc.).
This is COMPLETELY PREVENTABLE by using Docker as instructed.

üî¥ NO EXCUSES FOR:
- "ModuleNotFoundError: No module named 'psycopg2'"
- Missing build tools or compilers
- Package installation failures
- Environment setup issues

üü¢ SOLUTION: USE DOCKER
1. ALWAYS start by creating a Dockerfile with ALL dependencies
2. ALWAYS run your experiments inside the Docker container
3. ALWAYS use subprocess.run(['docker', 'run', ...]) for execution

EXAMPLE MANDATORY DOCKER SETUP:
```python
import subprocess
import os

def create_research_environment():
    dockerfile = '''FROM ubuntu:22.04
RUN apt-get update && apt-get install -y \\
    build-essential git libreadline-dev zlib1g-dev libssl-dev \\
    python3 python3-pip postgresql-client cmake sudo
RUN pip3 install psycopg2-binary pandas numpy scikit-learn lightgbm
WORKDIR /workspace
'''
    with open('Dockerfile', 'w') as f:
        f.write(dockerfile)

    subprocess.run(['docker', 'build', '-t', 'research-env', '.'], check=True)
    return True

def run_in_container(command):
    return subprocess.run([
        'docker', 'run', '--rm', '-v', f'{os.getcwd()}:/workspace',
        'research-env', 'bash', '-c', command
    ], capture_output=True, text=True)

# MANDATORY: Use this pattern for ALL operations
```

üö´ DO NOT attempt to install packages on the host system
üö´ DO NOT ignore dependency errors
üö´ DO NOT proceed without proper environment setup

‚úÖ DO create Docker environment first
‚úÖ DO run ALL commands inside containers
‚úÖ DO include ALL dependencies in Dockerfile
"""

def get_enhanced_system_prompt(original_prompt: str, research_domain: str = "general") -> str:
    """
    Enhance any system prompt with anti-fraud requirements
    """
    # Start with Docker requirement (most critical for fixing failures)
    enhanced_prompt = original_prompt + "\n\n" + DOCKER_MANDATORY_REQUIREMENTS

    # Add general anti-fraud requirements
    enhanced_prompt += "\n\n" + REAL_EXPERIMENTATION_REQUIREMENTS

    if "postgresql" in research_domain.lower() or "postgres" in research_domain.lower():
        enhanced_prompt += "\n\n" + POSTGRESQL_MODIFICATION_REQUIREMENTS

    if "htap" in research_domain.lower() or "query" in research_domain.lower():
        enhanced_prompt += "\n\n" + HTAP_RESEARCH_REQUIREMENTS

    # Always add implementation success guidance to prevent common failures
    enhanced_prompt += "\n\n" + IMPLEMENTATION_SUCCESS_PROMPTS

    return enhanced_prompt

PRE_EXECUTION_VALIDATION_PROMPT = """
üîç PRE-EXECUTION VALIDATION REQUIRED

Before running your code, explain:

1. DATA SOURCES: Where exactly will your data come from? (No "synthetic" or "generated" answers)
2. SYSTEM SETUP: What real systems will you install/modify? Show the commands.
3. MEASUREMENT METHOD: How will you measure real performance? (No simulated metrics)
4. VALIDATION PLAN: How will you prove your results are real and not synthetic?

Your code will be automatically validated for fraud before execution.
Any synthetic data generation will INVALIDATE your entire experiment.
"""

IMPLEMENTATION_SUCCESS_PROMPTS = """
üéØ IMPLEMENTATION SUCCESS GUIDANCE

To ensure your experiments succeed and don't fail with "nan" values or buggy implementations:

üîß START SIMPLE - BUILD INCREMENTALLY (USING DOCKER):

üê≥ STEP 0: Docker Environment Setup (CRITICAL FIRST STEP)
```python
import os
import subprocess
import time

def setup_docker_environment():
    # Create Docker environment with all dependencies pre-installed

    dockerfile_content = '''FROM ubuntu:22.04

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    build-essential git libreadline-dev zlib1g-dev libssl-dev \\
    libxml2-dev libxslt1-dev libicu-dev pkg-config python3 \\
    python3-pip python3-dev postgresql-client wget curl sudo cmake \\
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
RUN pip3 install psycopg2-binary pandas numpy scikit-learn lightgbm

WORKDIR /workspace

# Create non-root user
RUN useradd -m -s /bin/bash researcher && \\
    usermod -aG sudo researcher && \\
    echo "researcher ALL=(ALL) NOPASSWD:ALL" >> /etc/sudoers

USER researcher
'''

    with open('Dockerfile', 'w') as f:
        f.write(dockerfile_content)

    # Build Docker image
    subprocess.run(['docker', 'build', '-t', 'postgres-research', '.'], check=True)

    print("‚úÖ Docker environment created successfully")
    return True

def run_in_docker(command):
    # Execute command inside Docker container
    full_cmd = [
        'docker', 'run', '--rm', '-v', f'{os.getcwd()}:/workspace',
        'postgres-research', 'bash', '-c', command
    ]
    return subprocess.run(full_cmd, capture_output=True, text=True)

# CRITICAL: Always start with Docker setup
if __name__ == "__main__":
    setup_docker_environment()
```

STEP 1: Basic Setup Inside Docker (Get Something Working)
```python
def test_basic_setup_in_docker():
    # Test PostgreSQL setup inside Docker container

    setup_commands = '''
# Clone and build PostgreSQL
git clone https://github.com/postgres/postgres.git
cd postgres
git checkout REL_16_STABLE
./configure --prefix=$HOME/pgsql --enable-debug
make -j$(nproc)
make install

# Initialize database
$HOME/pgsql/bin/initdb -D $HOME/pgsql/data
$HOME/pgsql/bin/pg_ctl -D $HOME/pgsql/data -l $HOME/pgsql/logfile start

# Create test database
$HOME/pgsql/bin/createdb tpch

# Test connection
$HOME/pgsql/bin/psql -d tpch -c "SELECT version();"
'''

    result = run_in_docker(setup_commands)
    if result.returncode == 0:
        print("‚úÖ PostgreSQL setup successful in Docker")
        return True
    else:
        print(f"‚ùå Setup failed: {result.stderr}")
        return False

if __name__ == "__main__":
    if test_basic_setup_in_docker():
        print("‚úÖ Basic setup successful")
    else:
        print("‚ùå Setup failed - fix this before proceeding")
```

STEP 2: Data Loading Verification (Inside Docker)
```python
def verify_data_loading_in_docker():
    # Verify TPC-H data loading inside Docker container

    data_loading_commands = '''
# Set PATH for PostgreSQL
export PATH=$HOME/pgsql/bin:$PATH

# Download and build TPC-H tools
cd /workspace
git clone https://github.com/gregrahn/tpch-kit.git
cd tpch-kit/dbgen

# Patch makefile for modern systems
cp makefile.suite Makefile
sed -i 's/CC.*=/CC = gcc/' Makefile
sed -i 's/DATABASE.*=/DATABASE = POSTGRESQL/' Makefile
sed -i 's/MACHINE.*=/MACHINE = LINUX/' Makefile
sed -i 's/WORKLOAD.*=/WORKLOAD = TPCH/' Makefile

# Build and generate data
make
./dbgen -s 0.01  # Generate 10MB dataset for quick testing

# Create table schemas
psql -d tpch -c "
CREATE TABLE lineitem (
    l_orderkey bigint,
    l_partkey bigint,
    l_suppkey bigint,
    l_linenumber bigint,
    l_quantity decimal(15,2),
    l_extendedprice decimal(15,2),
    l_discount decimal(15,2),
    l_tax decimal(15,2),
    l_returnflag char(1),
    l_linestatus char(1),
    l_shipdate date,
    l_commitdate date,
    l_receiptdate date,
    l_shipinstruct char(25),
    l_shipmode char(10),
    l_comment varchar(44)
);"

# Load data
psql -d tpch -c "\\\\copy lineitem FROM 'lineitem.tbl' WITH DELIMITER '|';"

# Verify data loaded
psql -d tpch -c "SELECT count(*) as row_count FROM lineitem;"
'''

    result = run_in_docker(data_loading_commands)
    if result.returncode == 0:
        print("‚úÖ TPC-H data loaded successfully")
        print(f"Output: {result.stdout}")
        return True
    else:
        print(f"‚ùå Data loading failed: {result.stderr}")
        return False

def verify_data_loading():
    try:
        conn = psycopg2.connect("postgresql://localhost:5432/tpch")
        cursor = conn.cursor()

        # Test that data exists
        cursor.execute("SELECT count(*) FROM lineitem LIMIT 1;")
        count = cursor.fetchone()[0]

        if count > 0:
            print(f"‚úÖ Data loaded: {count} rows in lineitem")
            return count
        else:
            print("‚ùå No data found")
            return 0
    except Exception as e:
        print(f"‚ùå Data verification failed: {e}")
        return 0
```

STEP 3: Metric Calculation (PREVENT NaN VALUES)
```python
def calculate_metrics_safely():
    try:
        metrics = {}

        # Always initialize with default values
        metrics['accuracy'] = 0.0
        metrics['execution_time'] = float('inf')
        metrics['speedup'] = 1.0

        # Calculate actual metrics
        correct_predictions = 0
        total_predictions = 0

        # Ensure we have data to work with
        if total_predictions > 0:
            metrics['accuracy'] = correct_predictions / total_predictions
        else:
            print("‚ö†Ô∏è  No predictions made - setting accuracy to 0")
            metrics['accuracy'] = 0.0

        # Validate metrics before returning
        for key, value in metrics.items():
            if value is None or not isinstance(value, (int, float)):
                print(f"‚ö†Ô∏è  Invalid metric {key}: {value}, setting to 0")
                metrics[key] = 0.0
            elif key == 'accuracy' and (value < 0 or value > 1):
                print(f"‚ö†Ô∏è  Invalid accuracy {value}, clipping to [0,1]")
                metrics[key] = max(0.0, min(1.0, value))

        return metrics

    except Exception as e:
        print(f"‚ùå Metric calculation failed: {e}")
        return {'accuracy': 0.0, 'execution_time': float('inf'), 'speedup': 1.0}
```

üêõ DEBUGGING COMMON FAILURES:

1. **"All nodes marked as buggy" - Fix:**
   - Add try/catch around ALL code
   - Return valid metrics even if experiments fail
   - Test each component independently
   - Print debug information at each step

2. **"NaN metric values" - Fix:**
   - Initialize all metrics with default values
   - Check for division by zero
   - Validate data exists before calculations
   - Use safe math operations

3. **"No working implementation" - Fix:**
   - Start with minimal working example
   - Build complexity incrementally
   - Test each phase before moving to next
   - Have fallback implementations

üîÑ ITERATIVE DEVELOPMENT PATTERN:

Phase 1: Get basic database connection working
Phase 2: Load and verify small dataset
Phase 3: Run simple query on both engines
Phase 4: Compare execution times
Phase 5: Extract basic features
Phase 6: Train simple model
Phase 7: Evaluate and improve

üìä ALWAYS RETURN VALID METRICS:
```python
def ensure_valid_metrics(raw_metrics):
    \"\"\"Ensure metrics are valid numbers to prevent NaN failures\"\"\"
    safe_metrics = {}

    for key, value in raw_metrics.items():
        if value is None or str(value) == 'nan':
            safe_metrics[key] = 0.0
        elif isinstance(value, (int, float)) and not math.isfinite(value):
            safe_metrics[key] = 0.0
        else:
            safe_metrics[key] = float(value)

    return safe_metrics
```

REMEMBER: A working implementation with 60% accuracy is better than a broken implementation with NaN values!
"""